name: Run Benchmarks

on:
  workflow_dispatch:

jobs:
  benchmark:
    runs-on: ubuntu-latest
    outputs:
      artifact-name: ${{ steps.upload.outputs.artifact-name }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '9.0.x'

      - name: Test local NuGet package
        run: ./test-local-nuget.sh
        
      - name: Restore ConsoleTest project
        run: dotnet restore ConsoleTest/ConsoleTest.csproj

      - name: Build ConsoleTest project in Release mode
        run: dotnet build ConsoleTest/ConsoleTest.csproj --configuration Release --no-restore

      - name: List benchmarks
        run: |
          dotnet run --project ConsoleTest/ConsoleTest.csproj --configuration Release --no-build --maxWarmupCount 10 --list tree

      - name: Run benchmarks
        run: |
          dotnet run --project ConsoleTest/ConsoleTest.csproj --configuration Release --no-build --runtimes net9.0

      - name: Copy benchmark result
        run: |
          mkdir -p benchmark-output
          echo "Available files:"
          ls -R BenchmarkDotNet.Artifacts || echo "No artifacts directory"
          if [ -d BenchmarkDotNet.Artifacts ]; then
            cp -r BenchmarkDotNet.Artifacts/* benchmark-output/
          else
            echo "No BenchmarkDotNet.Artifacts directory found"
          fi

      - name: Ensure CSV(s) are available for comparison
        run: |
          shopt -s nullglob
          CSVFILES=(benchmark-output/results/*.csv)
          if [ ${#CSVFILES[@]} -gt 0 ]; then
            for f in "${CSVFILES[@]}"; do
              cp "$f" benchmark-output/
              echo "Copied $f to benchmark-output root."
            done
          else
            echo "No CSV files found in results folder."
          fi

      - name: Upload benchmark result
        id: upload
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-current
          path: benchmark-output

  compare:
    runs-on: ubuntu-latest
    needs: benchmark
    steps:
      - name: Install GitHub CLI
        run: sudo apt-get update && sudo apt-get install -y gh

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Get latest successful run ID on master
        id: get_run_id
        run: |
          RUN_ID=$(gh api \
            -H "Accept: application/vnd.github+json" \
            "/repos/${{ github.repository }}/actions/workflows/benchmarks.yml/runs?branch=master&status=success&per_page=1" \
            --jq ".workflow_runs[0].id")
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}

      - name: Get previous artifact ID for benchmark-current
        id: get_artifact_id
        run: |
          set -e
          ARTIFACT_ID=$(gh api \
            -H "Accept: application/vnd.github+json" \
            "/repos/${{ github.repository }}/actions/runs/${{ steps.get_run_id.outputs.run_id }}/artifacts" \
            --jq ".artifacts[] | select(.name==\"benchmark-current\") | .id" 2>&1 || true)
          if echo "$ARTIFACT_ID" | grep -q 'Not Found'; then
            echo "No previous benchmark-current artifact found (404). Skipping comparison."
            echo "artifact_id=" >> $GITHUB_OUTPUT
            exit 0
          fi
          echo "artifact_id=$ARTIFACT_ID" >> $GITHUB_OUTPUT
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}


      - name: Download previous benchmark-current artifact
        if: ${{ steps.get_artifact_id.outputs.artifact_id != '' }}
        run: |
          gh api \
            -H "Accept: application/vnd.github+json" \
            "/repos/${{ github.repository }}/actions/artifacts/${{ steps.get_artifact_id.outputs.artifact_id }}/zip" > previous.zip
          unzip -o previous.zip -d previous
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }} 

      - name: Download current result
        if: ${{ steps.get_artifact_id.outputs.artifact_id != '' }}
        uses: actions/download-artifact@v4
        with:
          name: benchmark-current
          path: current

      - name: Summarize benchmark diff with OpenAI
        if: ${{ steps.get_artifact_id.outputs.artifact_id != '' }}
        run: |
          pip install google-generativeai
          shopt -s nullglob
          PREV_CSV=(previous/*.csv)
          CUR_CSV=(current/*.csv)
          if [ ${#PREV_CSV[@]} -gt 0 ] && [ ${#CUR_CSV[@]} -gt 0 ]; then
            for prev in "${PREV_CSV[@]}"; do
              fname=$(basename "$prev")
              cur="current/$fname"
              if [ -f "$cur" ]; then
                GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }} python .github/scripts/ai_benchmark_diff.py "$prev" "$cur"
              fi
            done
          fi
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}


